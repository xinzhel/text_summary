{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Categories for All Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_domain(arxiv_id):\n",
    "    # arxiv_id = \"1810.04805\"\n",
    "    url = f'http://export.arxiv.org/api/query?id_list={arxiv_id}'\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.text)\n",
    "    categories = [cat.attrib['term'] for cat in root.iter('{http://www.w3.org/2005/Atom}category')]\n",
    "    return categories\n",
    "\n",
    "\n",
    "i = 5\n",
    "inp_path = '../arxiv-dataset/train' + str(i) +  '.txt'\n",
    "only_cat = []\n",
    "with open(inp_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    paper = json.loads(line)\n",
    "    paper['categories'] = query_domain(paper[\"article_id\"])\n",
    "    only_cat.append(paper['categories'])\n",
    "\n",
    "ids_for_cats = { 'cs': [], 'eco': [], 'eess': [], 'math': [], 'physics': [], 'q-bio': [], 'q-fin': [], 'stat': []}\n",
    "for i, cat in enumerate(only_cat):\n",
    "    if ' '.join(cat).startswith('cs'):\n",
    "        ids_for_cats['cs'].append(i)\n",
    "    if ' '.join(cat).startswith('eco'):\n",
    "        ids_for_cats['eco'].append(i)\n",
    "    if ' '.join(cat).startswith('eess'):\n",
    "        ids_for_cats['eess'].append(i)\n",
    "    if ' '.join(cat).startswith('math'):\n",
    "        ids_for_cats['math'].append(i)\n",
    "    if ' '.join(cat).startswith('physics'):\n",
    "        ids_for_cats['physics'].append(i)\n",
    "    if ' '.join(cat).startswith('q-bio'):\n",
    "        ids_for_cats['q-bio'].append(i)\n",
    "    if ' '.join(cat).startswith('q-fin'):\n",
    "        ids_for_cats['q-fin'].append(i)\n",
    "    if ' '.join(cat).startswith('stat'):\n",
    "        ids_for_cats['stat'].append(i)\n",
    "\n",
    "with open('ids_for_cats.pickle', 'wb') as handle:\n",
    "    pickle.dump(ids_for_cats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# import time\n",
    "# time.sleep(0.01)\n",
    "# paper = json.loads(lines[56])\n",
    "# query_domain(paper[\"article_id\"])\n",
    "\n",
    "len(only_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ids_for_cats.pickle', 'rb') as handle:\n",
    "    ids_for_cats2 = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs 66\n",
      "eco 0\n",
      "eess 0\n",
      "math 320\n",
      "physics 83\n",
      "q-bio 15\n",
      "q-fin 3\n",
      "stat 15\n",
      "502\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for domain, idx in ids_for_cats2.items():\n",
    "    total += len(idx)\n",
    "    print(domain, len(idx))\n",
    "print(total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate: query gpt3.5-turbo to categorize each sentence in the abstract into facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "inp_path = '../arxiv-dataset/train' + str(i) +  '.txt'\n",
    "only_cat = []\n",
    "with open(inp_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "papers = []\n",
    "for line in lines:\n",
    "    papers.append(json.loads(line))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the price to using the Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abstracts = []\n",
    "# for i in ids_for_cats2['cs']: \n",
    "#     abstracts.append(papers[i]['abstract_text'])\n",
    "\n",
    "with open('cs_abstracts.pickle', 'rb') as handle:\n",
    "    abstracts = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matrix data sets are common nowadays like in biomedical imaging where the diffusion tensor magnetic resonance imaging ( dt - mri ) modality produces data sets of 3d symmetric positive definite matrices anchored at voxel positions capturing the anisotropic diffusion properties of water molecules in biological tissues .  the space of symmetric matrices can be partially ordered using the lwner ordering , and computing extremal matrices dominating a given set of matrices is a basic primitive used in matrix - valued signal processing . in this letter , we design a fast and easy - to - implement iterative algorithm to approximate arbitrarily finely these extremal matrices .  finally , we discuss on extensions to matrix clustering .    '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore keywords\n",
    "abstract = abstracts[0]\n",
    "' '.join([sent[4: -4] for sent in abstract if \"* keywords\" not in sent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> in north - indian - music - system(nims),_tabl _ is mostly used as percussive accompaniment for vocal - music in polyphonic - compositions . </S>',\n",
       " '<S> the human auditory system uses perceptual grouping of musical - elements and easily filters the _ tabl _ </S>',\n",
       " '<S> component , thereby decoding prominent rhythmic features like _ tla _ , tempo from a polyphonic - composition . for western music , lots of work have been reported for automated drum analysis of polyphonic - composition . </S>',\n",
       " '<S> however , attempts at computational analysis of _ tla _ by separating the _ </S>',\n",
       " '<S> tabl_-signal from mixed signal in nims have not been successful . </S>',\n",
       " '<S> _ tabl _ is played with two components - right and left . </S>',\n",
       " '<S> the right - hand component has frequency overlap with voice and other instruments . </S>',\n",
       " '<S> so , _ tla _ analysis of polyphonic - composition , by accurately separating the _ </S>',\n",
       " '<S> tabl_-signal from the mixture is a baffling task , therefore an area of challenge . in this work </S>',\n",
       " '<S> we propose a novel technique for successfully detecting _ tla _ using left-_tabl _ signal , producing meaningful results because the left-_tabl _ normally does nt have frequency overlap with voice and other instruments . </S>',\n",
       " '<S> north - indian - rhythm follows complex cyclic pattern , against linear approach of western - rhythm . </S>',\n",
       " '<S> we have exploited this cyclic property along with stressed and non - stressed methods of playing _ </S>',\n",
       " '<S> tabl_-strokes to extract a characteristic pattern from the left-_tabl _ strokes , which , after matching with the grammar of _ tla_-system , determines the _ tla _ and tempo of the composition . </S>',\n",
       " '<S> a large number of polyphonic(vocal+__tabl__+other - instruments ) compositions has been analyzed with the methodology and the result clearly reveals the effectiveness of proposed techniques .    * </S>',\n",
       " '<S> * keywords:**left-_tabl _ drum , _ tla _ detection , tempo detection , polyphonic composition , cyclic pattern , north indian music system </S>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa722aa51baa7ca1a14ae10c51947100c8742c9283df2adfc9442d206b591bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
