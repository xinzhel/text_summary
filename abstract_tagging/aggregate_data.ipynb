{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the files with the affix \".xlsx\" in the current folder into one file\n",
    "\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the files with the affix \".xlsx\" in the current folder\n",
    "files = [file for file in os.listdir() if file.endswith(\".xlsx\")]\n",
    "\n",
    "# read all the files into a list of dataframes\n",
    "dfs = [pd.read_excel(file) for file in files]\n",
    "\n",
    "# merge all the dataframes into one dataframe\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# write the merged dataframe into a file\n",
    "df.to_excel(\"test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Index(['dataset_type', 'row_id', 'arxiv_id', 'category', 'abstract',\n",
      "       'Introduction/Background', 'Aim/Purpose', 'Methodology',\n",
      "       'Results / Contributions ', 'Conclusions',\n",
      "       'Limitations of Research / Gap', 'Not Sure', 'ERRORS', 'TOO LONG'],\n",
      "      dtype='object')\n",
      "  dataset_type  row_id    arxiv_id category  \\\n",
      "0        train   44884   1408.1268       cs   \n",
      "1        train   52749   1409.5561       cs   \n",
      "2        train   48309   cs0406058       cs   \n",
      "3        train  134998  1703.07247       cs   \n",
      "4        train   47466   cs0408044       cs   \n",
      "\n",
      "                                            abstract Introduction/Background  \\\n",
      "0  <S0> In this paper we develop an algorithm for...                      S0   \n",
      "1  <S0> We consider a network design problem call...                      S0   \n",
      "2  <S0> We present a protocol for verification of...                      S0   \n",
      "3  <S0> In the tree augmentation problem we are g...                S0,S1,S3   \n",
      "4  <S0> Flux is a programming method for the desi...                   S0,S1   \n",
      "\n",
      "  Aim/Purpose Methodology Results / Contributions  Conclusions  \\\n",
      "0         NaN         NaN                 S1,S3,S4          S5   \n",
      "1         NaN         NaN                 S1,S2,S3          S4   \n",
      "2         NaN          S1                      NaN         NaN   \n",
      "3       S1,S2         NaN                    S5,S6       S5,S6   \n",
      "4         NaN         NaN                       S2          S3   \n",
      "\n",
      "  Limitations of Research / Gap Not Sure ERRORS  TOO LONG  \n",
      "0                           NaN      NaN     S2       NaN  \n",
      "1                           NaN      NaN    NaN       NaN  \n",
      "2                           NaN      NaN     S2       NaN  \n",
      "3                           NaN      NaN     S4       NaN  \n",
      "4                           NaN      NaN     S4       NaN  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 14 elements, new values have 9 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m         facets_for_abstracts[\u001b[39mstr\u001b[39m(row[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39marticle_id\u001b[39m\u001b[39m'\u001b[39m])] \u001b[39m=\u001b[39m facets\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m abstracts, facets_for_abstracts\n\u001b[0;32m---> 36\u001b[0m abstracts, facets_for_abstracts \u001b[39m=\u001b[39m aggregate_abstracts(\u001b[39m\"\u001b[39;49m\u001b[39marxiv_computer-science.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[96], line 9\u001b[0m, in \u001b[0;36maggregate_abstracts\u001b[0;34m(FILE_NAME)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead())\n\u001b[0;32m----> 9\u001b[0m df\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39marticle_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBackground\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPurpose\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMethod\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mResult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mConclusions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLimitation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOthers\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m abstracts \u001b[39m=\u001b[39m {}\n\u001b[1;32m     12\u001b[0m facets_for_abstracts \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 5915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   5916\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   5917\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:823\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: AnyArrayLike \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py:230\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 14 elements, new values have 9 elements"
     ]
    }
   ],
   "source": [
    "def aggregate_abstracts(FILE_NAME):\n",
    "    # read the merged dataframe\n",
    "    df = pd.read_excel(FILE_NAME)\n",
    "    # print the number of rows in the merged dataframe\n",
    "    print(len(df))\n",
    "    \n",
    "    print(df.columns)\n",
    "    print(df.head())\n",
    "    if len(df.columns) == 9:\n",
    "        df.columns = ['article_id', 'abstract', 'Background', 'Purpose', 'Method', 'Result', 'Conclusions', 'Limitation', 'Others']\n",
    "    if len(df.columns) == 14:\n",
    "        df.columns = ['dataset_type', 'row_id', 'article_id', 'category', 'abstract', 'Background', 'Purpose', 'Method', 'Result', 'Conclusions', 'Limitation', 'Others',  'Errors', 'TooLong']\n",
    "        assert len(df.columns) == 14\n",
    "\n",
    "    \n",
    "    abstracts = {}\n",
    "    facets_for_abstracts = {}\n",
    "    for row in df.iterrows():\n",
    "        # split the abstract into sentences according to the tages <S0>, <S1>, <S2>, ...\n",
    "        sentences =  row[1]['abstract'].split(\"<S\")[1:]        \n",
    "        sentences = [sentence[sentence.find(\">\")+1:] for sentence in sentences] # get the content of each sentence\n",
    "        sentences = [sentence[:sentence.find(\"</S\")] for sentence in sentences] # remove the tags </S0>, </S1>, </S2>, ...\n",
    "\n",
    "        # extract facet for each sentence\n",
    "        facets = ['Others'] * len(sentences)\n",
    "        for i in range(len(sentences)):\n",
    "            identifier = 'S'+str(i)\n",
    "            for tag in [ 'Background', 'Purpose', 'Method', 'Result', 'Conclusions', 'Limitation', 'Others']:\n",
    "                sent_ids = row[1][tag]\n",
    "                if type(sent_ids) == float:\n",
    "                    continue\n",
    "                if identifier in sent_ids:\n",
    "                    facets[i] = tag\n",
    "                    break\n",
    "\n",
    "        abstracts[str(row[1]['article_id'])] = sentences\n",
    "        facets_for_abstracts[str(row[1]['article_id'])] = facets\n",
    "    return abstracts, facets_for_abstracts\n",
    "\n",
    "\n",
    "abstracts, facets_for_abstracts = aggregate_abstracts(\"arxiv_computer-science.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json file\n",
    "import json\n",
    "with open('test_abstracts.json', 'w') as fp:\n",
    "    json.dump(abstracts, fp)\n",
    "\n",
    "with open('test_facets.json', 'w') as fp:\n",
    "    json.dump(facets_for_abstracts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
